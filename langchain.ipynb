{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_valid_bin_indices(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "  \"\"\"Returns indices of bins in which item can fit.\"\"\"\n",
    "  return np.nonzero((bins - item) >= 0)[0]\n",
    "\n",
    "\n",
    "def online_binpack(\n",
    "    items: tuple[float, ...], bins: np.ndarray\n",
    ", priority) -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
    "  \"\"\"Performs online binpacking of `items` into `bins`.\"\"\"\n",
    "  # Track which items are added to each bin.\n",
    "  packing = [[] for _ in bins]\n",
    "  # Add items to bins.\n",
    "  for item in items:\n",
    "    # Extract bins that have sufficient space to fit item.\n",
    "    valid_bin_indices = get_valid_bin_indices(item, bins)\n",
    "    # Score each bin based on heuristic.\n",
    "    priorities = priority(item, bins[valid_bin_indices])\n",
    "    # Add item to bin with highest priority.\n",
    "    best_bin = valid_bin_indices[np.argmax(priorities)]\n",
    "    bins[best_bin] -= item\n",
    "    packing[best_bin].append(item)\n",
    "  # Remove unused bins from packing.\n",
    "  packing = [bin_items for bin_items in packing if bin_items]\n",
    "  return packing, bins\n",
    "\n",
    "\n",
    "# @funsearch.run\n",
    "def evaluate(instances: dict, priority) -> float:\n",
    "  \"\"\"Evaluate heuristic function on a set of online binpacking instances.\"\"\"\n",
    "  # List storing number of bins used for each instance.\n",
    "  num_bins = []\n",
    "  # Perform online binpacking for each instance.\n",
    "  for name in instances:\n",
    "    instance = instances[name]\n",
    "    capacity = instance['capacity']\n",
    "    items = instance['items']\n",
    "    # Create num_items bins so there will always be space for all items,\n",
    "    # regardless of packing order. Array has shape (num_items,).\n",
    "    bins = np.array([capacity for _ in range(instance['num_items'])])\n",
    "    # Pack items into bins and return remaining capacity in bins_packed, which\n",
    "    # has shape (num_items,).\n",
    "    _, bins_packed = online_binpack(items, bins, priority)\n",
    "    # If remaining capacity in a bin is equal to initial capacity, then it is\n",
    "    # unused. Count number of used bins.\n",
    "    num_bins.append((bins_packed != capacity).sum())\n",
    "  # Score of heuristic function is negative of average number of bins used\n",
    "  # across instances (as we want to minimize number of bins).\n",
    "  return -np.mean(num_bins)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_bound(items: tuple[int, ...], capacity: int) -> float:\n",
    "  \"\"\"Computes L1 lower bound on OPT for bin packing.\n",
    "\n",
    "  Args:\n",
    "    items: Tuple of items to pack into bins.\n",
    "    capacity: Capacity of bins.\n",
    "\n",
    "  Returns:\n",
    "    Lower bound on number of bins required to pack items.\n",
    "  \"\"\"\n",
    "  return np.ceil(np.sum(items) / capacity)\n",
    "\n",
    "\n",
    "def l1_bound_dataset(instances: dict) -> float:\n",
    "  \"\"\"Computes the mean L1 lower bound across a dataset of bin packing instances.\n",
    "\n",
    "  Args:\n",
    "    instances: Dictionary containing a set of bin packing instances.\n",
    "\n",
    "  Returns:\n",
    "    Average L1 lower bound on number of bins required to pack items.\n",
    "  \"\"\"\n",
    "  l1_bounds = []\n",
    "  for name in instances:\n",
    "    instance = instances[name]\n",
    "    l1_bounds.append(l1_bound(instance['items'], instance['capacity']))\n",
    "  return np.mean(l1_bounds)\n",
    "\n",
    "def get_opt_num_bins(instance):\n",
    "    return l1_bound_dataset(instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_function(chat_response: dict, instances: dict,\n",
    "#                  database:dict, num_item: int, \n",
    "#                  eval_fun, parents_code: list) -> dict:\n",
    "    \n",
    "#     if 'intuition' in chat_response.keys() and 'code' in chat_response.keys():\n",
    "#         d ={}\n",
    "#         string = chat_response['code']\n",
    "#         exec(string, globals(),d)\n",
    "#         print(d)\n",
    "#         priority = d['priority']\n",
    "#         opt_num_bins = get_opt_num_bins(instances)\n",
    "#         avg_num_bins = -eval_fun(instances, priority)\n",
    "#         score = (avg_num_bins - opt_num_bins) / opt_num_bins\n",
    "#         scores = database.keys()\n",
    "#         if str(score) in scores:\n",
    "#             print(f'出现重复了:{num_item}')\n",
    "#             score+=1\n",
    "#         database[f\"{score}\"] = {\"code\": chat_response[\"code\"], \n",
    "#                               \"Intuition\": chat_response[\"intuition\"],\n",
    "#                               \"num_item\": num_item,\n",
    "#                               \"parents\": parents_code}\n",
    "#     else:\n",
    "#         print('回答有问题')\n",
    "        \n",
    "#     return database\n",
    "\n",
    "import importlib\n",
    "def update_function(chat_response: dict, instances: dict,\n",
    "                 database:dict, num_item: int, \n",
    "                 eval_fun, parents_code: list) -> dict:\n",
    "    \n",
    "    #if 'intuition' in chat_response.keys() and 'code' in chat_response.keys():\n",
    "    if 'code' in chat_response.keys():\n",
    "        module_name = f\"my_function_{num_item}\"\n",
    "        with open(f'./cody/{module_name}.py', 'w') as file:\n",
    "            file.write('import numpy as np \\n' + chat_response['code'])\n",
    "        module = importlib.import_module('cody.'+module_name)\n",
    "        priority = getattr(module, 'priority')\n",
    "        opt_num_bins = get_opt_num_bins(instances)\n",
    "        avg_num_bins = -eval_fun(instances, priority)\n",
    "        score = (avg_num_bins - opt_num_bins) / opt_num_bins\n",
    "        scores = database.keys()\n",
    "        print(score)\n",
    "        if str(score) in scores:\n",
    "            print(f'出现重复了:{num_item}')\n",
    "            database[f\"{score} 数值重复\"] = {\"code\": chat_response[\"code\"], \n",
    "                                #\"Intuition\": chat_response[\"intuition\"],\n",
    "                                \"num_item\": num_item,\n",
    "                                \"parents\": parents_code}\n",
    "        else:\n",
    "            database[f\"{score}\"] = {\"code\": chat_response[\"code\"], \n",
    "                                #\"Intuition\": chat_response[\"intuition\"],\n",
    "                                \"num_item\": num_item,\n",
    "                                \"parents\": parents_code}\n",
    "    else:\n",
    "        print('回答有问题')\n",
    "        \n",
    "    return database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''我把字典的score作为key, 这样好排列, 初始化的时候记得算一下key'''\n",
    "import json\n",
    "import random\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "def opt(llm,res_fun , instances, input_database, expect_num=100, out_database = {}, \n",
    "        pick_type = 'random', top =5):\n",
    "    \n",
    "    prompt_template = ChatPromptTemplate(messages=[SystemMessagePromptTemplate.from_template(\n",
    "        'You are an expert in combinatorial optimization and online bin-packing problem. Your are very good at python programming.'),\n",
    "                                      HumanMessagePromptTemplate.from_template(\"\"\"\n",
    "Your task is to generate one new heuristic for online 1d binpacking. The requirements are as follows:\n",
    "1. The heuristic only takes two input: \n",
    "    item: float, size of item to be added to the bin\n",
    "    bins: numpy array, array of capacities for each bin\n",
    "2. The heuristic only returns the priority score of each bin as an array of the same size as input `bins`.\n",
    "3. The heuristic serves as a score function in a <|bin-packing solver|>.                                                                            \n",
    "4. Two <|example heuristic|> are listed below.\n",
    "5. Only generate one new heuristic at a time.\n",
    "                                                                                \n",
    "                                                                                                                                                             \n",
    "                                                                               \n",
    "<|evaluation function|>\n",
    "```python\n",
    "def online_binpack(\n",
    "    items: tuple[float, ...], bins: np.ndarray\n",
    ") -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
    "  \\\"\\\"\\\"Performs online binpacking of `items` into `bins`.\\\"\\\"\\\"\n",
    "  # Track which items are added to each bin.\n",
    "  packing = [[] for _ in bins]\n",
    "  # Add items to bins.\n",
    "  for item in items:\n",
    "    # Extract bins that have sufficient space to fit item.\n",
    "    valid_bin_indices = get_valid_bin_indices(item, bins)\n",
    "    # Score each bin based on heuristic.\n",
    "    priorities = priority(item, bins[valid_bin_indices])\n",
    "    # Add item to bin with highest priority.\n",
    "    best_bin = valid_bin_indices[np.argmax(priorities)]\n",
    "    bins[best_bin] -= item\n",
    "    packing[best_bin].append(item)\n",
    "  # Remove unused bins from packing.\n",
    "  packing = [bin_items for bin_items in packing if bin_items]\n",
    "  return packing, bins                                                                              \n",
    "```\n",
    "                                                                            \n",
    "<|example heuristic 1|>\n",
    "\n",
    "<Code>:   \n",
    "```python \n",
    "{code1}\n",
    "```\n",
    "\n",
    "<|example heuristic 2|>\n",
    "                                                                               \n",
    "<Code>:   \n",
    "```python                                                                                                                                                                                                                                \n",
    "{code2}\n",
    "``` \n",
    "                                                                                                                                                            \n",
    "<|generated heuristic|>                                                                        \n",
    "\"\"\")],input_variables=[\"code1\",\"code2\"])\n",
    "    for num_item in range(expect_num):\n",
    "        if pick_type == 'random':\n",
    "            key0, key1 = random.sample(list(input_database.keys()), 2)\n",
    "            \n",
    "        elif pick_type == 'top':\n",
    "            database_orderd = sorted(list(input_database.keys()))\n",
    "            candidate = database_orderd[:top]\n",
    "            key0, key1 = random.sample(candidate, 2)\n",
    "\n",
    "        value0 = input_database[key0]\n",
    "        value1 = input_database[key1]\n",
    "        # code1, intuition1 = value0['code'], value0['Intuition']\n",
    "        # code2, intuition2 = value1['code'], value1['Intuition']\n",
    "        code1 = value0['code']\n",
    "        code2 = value1['code']\n",
    "        parents_code = [key0, key1]\n",
    "        prompt_message = prompt_template.format_prompt( \n",
    "                                                       code1=code1, \n",
    "                                                       code2=code2)\n",
    "        with get_openai_callback() as cb:\n",
    "            answer = llm(prompt_message.to_messages()).content\n",
    "            print(answer)\n",
    "            response = res_fun(answer)\n",
    "            print(cb)\n",
    "        if response != None:\n",
    "            \n",
    "            out_database = update_function(response, instances, out_database, num_item, evaluate, parents_code)\n",
    "        else:\n",
    "            print('wrong format of generation, regenerate')\n",
    "            continue\n",
    "    return out_database\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. 创建数据集'''\n",
    "from prepapre import test_dataset_generataion\n",
    "\n",
    "test_data = test_dataset_generataion(20, 120, 150)\n",
    "valid_data = test_dataset_generataion(20, 250, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"2. 初始化database\"\"\"\n",
    "#google 生成的代码\n",
    "\n",
    "\n",
    "import json\n",
    "with open('new_database.json', 'r') as f:\n",
    "  database = f.read()\n",
    "  database = json.loads(database)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"3. 写LLM\"\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name = \"gpt-4\",\n",
    "                 temperature=0.75,\n",
    "                 openai_api_key=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_fun(answer):\n",
    "    '''\n",
    "    input:\n",
    "        answer: model answer, String\n",
    "    \n",
    "    output:\n",
    "        response: \n",
    "            - {\"intuition\": intuition, \"code\": code}, Dict\n",
    "            - return None if the the format of answer is wrong, which ill trigger regeneration\n",
    "    '''\n",
    "\n",
    "    idx1 = -1\n",
    "    idx2 = -1\n",
    "    idx3 = -1\n",
    "    idx4 = -1\n",
    "    answer_split = answer.split('\\n')\n",
    "    for i in range(len(answer_split)):\n",
    "        if '<Intuition>' in answer_split[i]:\n",
    "            idx1 = i\n",
    "        elif '<Code>' in answer_split[i]:\n",
    "            idx2 = i\n",
    "        elif '```python' in answer_split[i]:\n",
    "            idx3 = i\n",
    "        elif answer_split[i] == '```':\n",
    "            idx4 = i\n",
    "\n",
    "    if -1 not in [ idx3, idx4]:\n",
    "        #intuition = ' '.join(answer_split[(idx1):idx2])\n",
    "        code = '\\n'.join(answer_split[idx3+1:idx4])\n",
    "\n",
    "        #return {\"intuition\": intuition[12:], \"code\": code}\n",
    "        return {\"code\": code}\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Code>:\n",
      "```python\n",
      "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
      "    \"\"\"Heuristic that prioritizes bins based on the ratio of item size to the bin capacity.\"\"\"\n",
      "    return item / bins\n",
      "```\n",
      "Tokens Used: 573\n",
      "\tPrompt Tokens: 524\n",
      "\tCompletion Tokens: 49\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.018660000000000003\n",
      "0.0633299284984677\n",
      "<Code>:\n",
      "```python \n",
      "def priority(item: float, bins: np.ndarray) -> np.ndarray:\n",
      "    \"\"\"Heuristic that prioritizes bins based on the square root of the difference between the bin capacity and the item size.\"\"\"\n",
      "    return np.sqrt(bins - item)\n",
      "```\n",
      "Tokens Used: 569\n",
      "\tPrompt Tokens: 512\n",
      "\tCompletion Tokens: 57\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $0.01878\n",
      "1.4514811031664963\n"
     ]
    }
   ],
   "source": [
    "\"整合\"\n",
    "\n",
    "out_database = opt(llm=llm, res_fun = res_fun, instances= test_data, input_database=database ,\n",
    "                   expect_num=2, pick_type='top', top=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0.0633299284984677': {'code': 'def priority(item: float, bins: np.ndarray) -> np.ndarray:\\n    \"\"\"Heuristic that prioritizes bins based on the ratio of item size to the bin capacity.\"\"\"\\n    return item / bins',\n",
       "  'num_item': 0,\n",
       "  'parents': ['0.0599173553719008', '0.06301652892561993 数值重复']},\n",
       " '1.4514811031664963': {'code': 'def priority(item: float, bins: np.ndarray) -> np.ndarray:\\n    \"\"\"Heuristic that prioritizes bins based on the square root of the difference between the bin capacity and the item size.\"\"\"\\n    return np.sqrt(bins - item)',\n",
       "  'num_item': 1,\n",
       "  'parents': ['0.06404958677685954', '0.06301652892561993']}}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_dir = json.dumps(new_database, indent=4)\n",
    "# with open('new_database.json', 'w') as j:\n",
    "#     j.write(json_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
