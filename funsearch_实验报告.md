基本实验思路:

<img src="./assets/ea7dad6d39582a51399b8a51e712357.jpg" alt="ea7dad6d39582a51399b8a51e712357" style="zoom:30%;" />

最大的问题:

GPT-4**自己就会重复**. 分析可能的原因:

1. prompt的问题. 

   1.1 初始化Intuition的时候需要调整表述, 我们目前是空置.

   1.2 对GPT4做的提示不够精确, 代码实例使得他按照惯性思维延续. 如果改成"我们已经有...请不要生成类似的, 尝试新的生成..."或许会好.

   1.3 为了更好地写代码, 我们把score没有保存在database里面, 这可能是gpt无法正确地提高代码性能的一个原因.

2. 目前尝试的太少. 如果随着次数增多, 我们的database增加, 能够提供给GPT的prompt也会多样, 不知道代码会如何变化.

3. 关于GPT自己生成函数的错误率: 存在错误或者warning, 但是Google他们很聪明地把任务拆解, 使得LLM生成的代码本身并不复杂, 但代价就是这一部分的压力给到了prompt上. 





问题: 我们的最终目标是让gpt复现甚至超越小罗老师的工作. 现在的问题:

1. gpt-4都有重复的问题, 如果用更差的模型比如llama等效果不会更好.
2. 哪怕可以解决这个问题, 如何微调?

上策: 50篇论文全部微调. (微调本身的问题, 包括知识注入的方法, 对模型通用能力的影响)

中策: 50个代码放到prompt中, hugging gpt
