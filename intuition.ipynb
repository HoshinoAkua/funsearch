{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_valid_bin_indices(item: float, bins: np.ndarray) -> np.ndarray:\n",
    "  \"\"\"Returns indices of bins in which item can fit.\"\"\"\n",
    "  return np.nonzero((bins - item) >= 0)[0]\n",
    "\n",
    "\n",
    "def online_binpack(\n",
    "    items: tuple[float, ...], bins: np.ndarray\n",
    ", priority) -> tuple[list[list[float, ...], ...], np.ndarray]:\n",
    "  \"\"\"Performs online binpacking of `items` into `bins`.\"\"\"\n",
    "  # Track which items are added to each bin.\n",
    "  packing = [[] for _ in bins]\n",
    "  # Add items to bins.\n",
    "  for item in items:\n",
    "    # Extract bins that have sufficient space to fit item.\n",
    "    valid_bin_indices = get_valid_bin_indices(item, bins)\n",
    "    # Score each bin based on heuristic.\n",
    "    priorities = priority(item, bins[valid_bin_indices])\n",
    "    # Add item to bin with highest priority.\n",
    "    best_bin = valid_bin_indices[np.argmax(priorities)]\n",
    "    bins[best_bin] -= item\n",
    "    packing[best_bin].append(item)\n",
    "  # Remove unused bins from packing.\n",
    "  packing = [bin_items for bin_items in packing if bin_items]\n",
    "  return packing, bins\n",
    "\n",
    "\n",
    "# @funsearch.run\n",
    "def evaluate(instances: dict, priority) -> float:\n",
    "  \"\"\"Evaluate heuristic function on a set of online binpacking instances.\"\"\"\n",
    "  # List storing number of bins used for each instance.\n",
    "  num_bins = []\n",
    "  # Perform online binpacking for each instance.\n",
    "  for name in instances:\n",
    "    instance = instances[name]\n",
    "    capacity = instance['capacity']\n",
    "    items = instance['items']\n",
    "    # Create num_items bins so there will always be space for all items,\n",
    "    # regardless of packing order. Array has shape (num_items,).\n",
    "    bins = np.array([capacity for _ in range(instance['num_items'])])\n",
    "    # Pack items into bins and return remaining capacity in bins_packed, which\n",
    "    # has shape (num_items,).\n",
    "    _, bins_packed = online_binpack(items, bins, priority)\n",
    "    # If remaining capacity in a bin is equal to initial capacity, then it is\n",
    "    # unused. Count number of used bins.\n",
    "    num_bins.append((bins_packed != capacity).sum())\n",
    "  # Score of heuristic function is negative of average number of bins used\n",
    "  # across instances (as we want to minimize number of bins).\n",
    "  return -np.mean(num_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l1_bound(items: tuple[int, ...], capacity: int) -> float:\n",
    "  \"\"\"Computes L1 lower bound on OPT for bin packing.\n",
    "\n",
    "  Args:\n",
    "    items: Tuple of items to pack into bins.\n",
    "    capacity: Capacity of bins.\n",
    "\n",
    "  Returns:\n",
    "    Lower bound on number of bins required to pack items.\n",
    "  \"\"\"\n",
    "  return np.ceil(np.sum(items) / capacity)\n",
    "\n",
    "\n",
    "def l1_bound_dataset(instances: dict) -> float:\n",
    "  \"\"\"Computes the mean L1 lower bound across a dataset of bin packing instances.\n",
    "\n",
    "  Args:\n",
    "    instances: Dictionary containing a set of bin packing instances.\n",
    "\n",
    "  Returns:\n",
    "    Average L1 lower bound on number of bins required to pack items.\n",
    "  \"\"\"\n",
    "  l1_bounds = []\n",
    "  for name in instances:\n",
    "    instance = instances[name]\n",
    "    l1_bounds.append(l1_bound(instance['items'], instance['capacity']))\n",
    "  return np.mean(l1_bounds)\n",
    "\n",
    "def get_opt_num_bins(instance):\n",
    "    return l1_bound_dataset(instance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 搭建两个llm, 其中一个负责产生代码, 其中一个负责生成intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这次搭建的databse是用num_iter作为key的.\n",
    "\n",
    "import importlib\n",
    "def update_function(code_response: str, intuition_response: str , instances: dict,\n",
    "                    database: dict, num_item: int,\n",
    "                    eval_fun, parents: list) -> dict:\n",
    "    #模型生成的code, intuition_response 来自于不同的两个步骤.\n",
    "    module_name = f\"my_function_{num_item}\"\n",
    "    with open(f'./cody/{module_name}.py', 'w') as file:\n",
    "        file.write('import numpy as np \\n' + code_response)\n",
    "    module = importlib.import_module('cody.'+module_name)\n",
    "    priority = getattr(module, 'priority')\n",
    "    opt_num_bins = get_opt_num_bins(instances)\n",
    "    avg_num_bins = -eval_fun(instances, priority)\n",
    "    score = (avg_num_bins - opt_num_bins) / opt_num_bins\n",
    "    scores = database.keys()\n",
    "    if str(score) in scores:\n",
    "        print('出现重复')\n",
    "        database[f\"{num_item}\"] = {\"is_repeat\": True,\n",
    "                                   \"score\": score, \"parents\": parents,\n",
    "                                   \"code\": code_response, \"intuition\": intuition_response}\n",
    "    else: \n",
    "        database[f\"{num_item}\"] = {\"is_repeat\": False,\n",
    "                                   \"score\": score, \"parents\": parents,\n",
    "                                   \"code\": code_response, \"intuition\": intuition_response}\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.callbacks import get_openai_callback\n",
    "''' 设计思路是:\n",
    "1. 给gpt_1的prompt喂两个intuition, \n",
    "2. 然后把gpt_1生成的intuition喂给gpt_2\n",
    "'''\n",
    "\n",
    "def opt(llm_code, llm_response, \n",
    "        code_prompt: str, intuition_prompt: str, Meta_prompt : str,\n",
    "        input_database: dict, expect_num=100, out_database = {},\n",
    "        pick_type = 'top', top = 5) -> dict:\n",
    "    intuition_prompt_template = ChatPromptTemplate(messages=[SystemMessagePromptTemplate.from_template(Meta_prompt),\n",
    "                                              HumanMessagePromptTemplate.from_template(intuition_prompt)], \n",
    "                                              input_variables=['intuition1','intuition2'])\n",
    "    for num_item in range(expect_num):\n",
    "        if pick_type == 'random':\n",
    "            key0, key1 = random.sample(list(input_database.keys()), 2)\n",
    "        elif pick_type == 'top':\n",
    "            database_ordered = sorted(input_database.items(), key = lambda x: x[1][\"score\"])[:top]\n",
    "            candidate = random.sample(database_ordered, 2)\n",
    "            key0, key1 = candidate[0][0], candidate[1][0]\n",
    "            \n",
    "        \n",
    "        value0,value1 = input_database[key0], input_database[key1]\n",
    "        #code1, code2 = value0['code'], value1['code'] 似乎code没必要写出来...\n",
    "        intuition1, intuition2 = value0['intuition'], value1['intuition']\n",
    "        parents = [key0, key1]\n",
    "        prompt_message = intuition_prompt_template.format_prompt(#这里可以修改, 应该修改一下1\n",
    "            intuition1 = intuition1,\n",
    "            intuition2 = intuition2\n",
    "        )\n",
    "        with get_openai_callback() as cb:\n",
    "            answer = llm_code()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, {'a': 3, 'b': 4}), (1, {'a': 1, 'b': 2})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct = {1: {'a':1, 'b':2}, 2: {'a':3, 'b':4}}\n",
    "dct = sorted(dct.items(), key = lambda x: x[1][\"a\"], reverse=True)\n",
    "dct"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
